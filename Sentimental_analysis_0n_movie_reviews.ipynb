{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.tsv',delimiter=\"\\t\")\n",
    "test=pd.read_csv('test.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and \n",
    "# statistical natural language processing for English written in the Python programming language.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#TQDM is a progress bar library with good support for nested loops and Jupyter/IPython notebooks.\n",
    "#from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(123)\n",
    "random.seed(123)\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for cleaning the reviews, tokenize and lemmatize them.\n",
    "This function will take each phrase iteratively and it will\n",
    "\n",
    "    remove html content\n",
    "    remove non-alphabetic characters\n",
    "    tokenize the sentences\n",
    "    lemmatize each word to its lemma\n",
    "and then return the result in the list named reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in (df['Phrase']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "        \n",
    "        stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "        # 5. Remove stop words\n",
    "        meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=clean_sentences(train)\n",
    "test_sentences =clean_sentences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the dependent values and convert to one-hot encoded output using to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train.Sentiment.values\n",
    "y_target=to_categorical(target)\n",
    "num_classes=y_target.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geting the no of unique words and max length of a review available in the list of cleaned reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13619\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "unique_words = set()\n",
    "len_max = 0\n",
    "\n",
    "for sent in (X_train):\n",
    "    \n",
    "    unique_words.update(sent)\n",
    "    \n",
    "    if(len_max<len(sent)):\n",
    "        len_max = len(sent)\n",
    "        \n",
    "#length of the list of unique_words gives the no of unique words\n",
    "print(len(list(unique_words)))\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## actual tokenizer of keras and convert to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
    "tokenizer.fit_on_texts(list(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124848, 30) (31212, 30) (66292, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
    "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
    "\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping to prevent overfitting\n",
    "Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset. In this tutorial, you will discover the Keras API for adding early stopping to overfit deep learning neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
    "callback = [early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Model using Keras LSTM\n",
    "\n",
    "#Multilayer Perceptron (MLP) for multi-class softmax classification:\n",
    "#Let’s build what’s probably the most popular type of model in NLP at the moment: Long Short Term Memory network. \n",
    "#This architecture is specially designed to work on sequence data.\n",
    "#It fits perfectly for many NLP tasks like tagging and text classification.\n",
    "#It treats the text as a sequence rather than a bag of words or as ngrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 300)           4085700   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 128)           219648    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               6500      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 4,361,761\n",
      "Trainable params: 4,361,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
    "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "#model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124848 samples, validate on 31212 samples\n",
      "Epoch 1/6\n",
      "124848/124848 [==============================] - 134s 1ms/sample - loss: 1.0636 - acc: 0.5721 - val_loss: 0.8822 - val_acc: 0.6389\n",
      "Epoch 2/6\n",
      "124848/124848 [==============================] - 144s 1ms/sample - loss: 0.8477 - acc: 0.6584 - val_loss: 0.8457 - val_acc: 0.6555\n",
      "Epoch 3/6\n",
      "124848/124848 [==============================] - 145s 1ms/sample - loss: 0.7880 - acc: 0.6782 - val_loss: 0.8484 - val_acc: 0.6536\n",
      "Epoch 4/6\n",
      "124848/124848 [==============================] - 147s 1ms/sample - loss: 0.7639 - acc: 0.6871 - val_loss: 0.8670 - val_acc: 0.6509\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, Y_train, validation_data=(X_val, Y_val),epochs=6, batch_size=512, verbose=1, callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #This is done for learning purpose only. One can play around with different hyper parameters combinations\n",
    "#and try increase the accuracy even more. For example, a different learning rate, an extra dense layer \n",
    " before output layer, etc. Cross validation could be used to evaluate the model and grid search \n",
    "#further to find unique combination of parameters that give maximum accuracy. This model has a validation\n",
    "#accuracy of around 66.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "# Visualize learning curve. Here learning curve is not ideal. It should be much smoother as it decreases.\n",
    "#As mentioned before, altering different hyper parameters especially learning rate can have a positive impact\n",
    "#on accuracy and learning curve.\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "\n",
    "sub_file = pd.read_csv('sampleSubmission .csv',sep=',')\n",
    "sub_file.Sentiment=y_pred\n",
    "sub_file.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
