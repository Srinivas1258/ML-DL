{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecting sentiments of a quote.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7Xni5tucv0Zqfq/Jx7yLj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srinivas1258/ML-DL/blob/master/Detecting_sentiments_of_a_quote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TegJWjCIzH0u",
        "colab_type": "text"
      },
      "source": [
        "You work as a social media moderator for your firm. Your key responsibility is to tag uploaded content (images) during Pride Month based on its sentiment (positive, negative, or random) and categorize them for internal reference and SEO optimization.\n",
        "\n",
        "Task\n",
        "Your task is to build an engine that combines the concepts of OCR and NLP that accepts a .jpg file as input, extracts the text, if any, and classifies sentiment as positive or negative. If the text sentiment is neutral or an image file does not have any text, then it is classified as random.\n",
        "\n",
        "Data\n",
        "You must use an external dataset to train your model. The attached dataset link contains the sample data of each category [Positive | Negative | Random] and test data.\n",
        "\n",
        "Data files\n",
        "\n",
        "File name\tDescription\n",
        "Test.zip\tContains image files to be classified\n",
        "Sample.zip\tContains sample image files belonging to each category\n",
        "Test.csv\tPredictions file containing indices of test data and a blank target column\n",
        "sample_submission.csv\tSubmission format to be followed for uploading predictions\n",
        "Data description\n",
        "\n",
        "Column name\tDescription\n",
        "\n",
        "\n",
        "Filename\tFile name of test data image\n",
        "\n",
        "Category\tTarget column [values: 'Positive'/'Negative'/'Random']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3RcxVgwy5zf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "09c56a7f-bcf9-41b1-e5ef-6285162b870b"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 2s (2,847 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 2s (1,320 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 144426 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlIzevRzvjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3e4c9cae-52e8-4b60-ef1f-e7b0607ff627"
      },
      "source": [
        "! pip install Pillow\n",
        "! pip install pytesseract"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/d8/521db389ff0aae32035bfda6ed39cb2c2e28521c47015f6431f07460c50a/pytesseract-0.3.4.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.4-py2.py3-none-any.whl size=13431 sha256=c9160c5c83a50484fcb7d1ff181ab15123899fa39c9791cfacd1aef77228a5b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/a0/7596d2e0a73cf0aeffd6f6170862c4e73f3763b7827e48691a\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXTrQeBq2oRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9_nRqJIz7yo",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9c5ee611-4d6d-4bdd-a268-e8ccc58b1461"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5435c31-f3d6-45b8-bd4e-20412a74a125\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5435c31-f3d6-45b8-bd4e-20412a74a125\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving quote.zip to quote.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IVFxKUF7Fmf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a5ddccd-2f44-4e8a-a0ad-1bf68a854695"
      },
      "source": [
        "!unzip quote.zip"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  quote.zip\n",
            "   creating: Data Files/\n",
            "   creating: Data Files/Dataset/\n",
            "  inflating: Data Files/Dataset/Test903.jpg  \n",
            "  inflating: Data Files/Dataset/Test2434.jpg  \n",
            "  inflating: Data Files/Dataset/Test145.jpg  \n",
            "  inflating: Data Files/Dataset/Test1615.jpg  \n",
            "  inflating: Data Files/Dataset/Test1122.jpg  \n",
            "  inflating: Data Files/Dataset/Test132.jpg  \n",
            "  inflating: Data Files/Dataset/Test2959.jpg  \n",
            "  inflating: Data Files/Dataset/Test109.jpg  \n",
            "  inflating: Data Files/Dataset/Test114.jpg  \n",
            "  inflating: Data Files/Dataset/Test230.jpg  \n",
            "  inflating: Data Files/Dataset/Test536.jpg  \n",
            "  inflating: Data Files/Dataset/Test516.jpg  \n",
            "  inflating: Data Files/Dataset/Test233.jpg  \n",
            "  inflating: Data Files/Dataset/Test2792.jpg  \n",
            "  inflating: Data Files/Dataset/Test119.jpg  \n",
            "  inflating: Data Files/Dataset/Test2616.jpg  \n",
            "  inflating: Data Files/Dataset/Test1934.jpg  \n",
            "  inflating: Data Files/Dataset/Test803.jpg  \n",
            "  inflating: Data Files/Dataset/Test3030.jpg  \n",
            "  inflating: Data Files/Dataset/Test240.jpg  \n",
            "  inflating: Data Files/Dataset/Test107.jpg  \n",
            "  inflating: Data Files/Dataset/Test212.jpg  \n",
            "  inflating: Data Files/Dataset/Test2870.jpg  \n",
            "  inflating: Data Files/Dataset/Test757.jpg  \n",
            "  inflating: Data Files/Dataset/Test245.jpg  \n",
            "  inflating: Data Files/Dataset/Test243.jpg  \n",
            "  inflating: Data Files/Dataset/Test1923.jpg  \n",
            "  inflating: Data Files/Dataset/Test3177.jpg  \n",
            "  inflating: Data Files/Dataset/Test103.jpg  \n",
            "  inflating: Data Files/Dataset/Test482.jpg  \n",
            "  inflating: Data Files/Dataset/Test890.jpg  \n",
            "  inflating: Data Files/Dataset/Test372.jpg  \n",
            "  inflating: Data Files/Dataset/Test2648.jpg  \n",
            "  inflating: Data Files/Dataset/Test1353.jpg  \n",
            "  inflating: Data Files/Dataset/Test812.jpg  \n",
            "  inflating: Data Files/Dataset/Test1271.jpg  \n",
            "  inflating: Data Files/Dataset/Test523.jpg  \n",
            "  inflating: Data Files/Dataset/Test129.jpg  \n",
            "  inflating: Data Files/Dataset/Test140.jpg  \n",
            "  inflating: Data Files/Dataset/Test581.jpg  \n",
            "  inflating: Data Files/Dataset/Test353.jpg  \n",
            "  inflating: Data Files/Dataset/Test1012.jpg  \n",
            "  inflating: Data Files/Dataset/Test779.jpg  \n",
            "  inflating: Data Files/Dataset/Test141.jpg  \n",
            "  inflating: Data Files/Dataset/Test179.jpg  \n",
            "  inflating: Data Files/Dataset/Test113.jpg  \n",
            "  inflating: Data Files/Dataset/Test1359.jpg  \n",
            "  inflating: Data Files/Dataset/Test162.jpg  \n",
            "  inflating: Data Files/Dataset/Test198.jpg  \n",
            "  inflating: Data Files/Dataset/Test151.jpg  \n",
            "  inflating: Data Files/Dataset/Test1022.jpg  \n",
            "  inflating: Data Files/Dataset/Test125.jpg  \n",
            "  inflating: Data Files/Dataset/Test449.jpg  \n",
            "  inflating: Data Files/Dataset/Test213.jpg  \n",
            "  inflating: Data Files/Dataset/Test2235.jpg  \n",
            "  inflating: Data Files/Dataset/Test789.jpg  \n",
            "  inflating: Data Files/Dataset/Test833.jpg  \n",
            "  inflating: Data Files/Dataset/Test1279.jpg  \n",
            "  inflating: Data Files/Dataset/Test533.jpg  \n",
            "  inflating: Data Files/Dataset/Test105.jpg  \n",
            "  inflating: Data Files/Dataset/Test134.jpg  \n",
            "  inflating: Data Files/Dataset/Test3706.jpg  \n",
            "  inflating: Data Files/Dataset/Test3625.jpg  \n",
            "  inflating: Data Files/Dataset/Test172.jpg  \n",
            "  inflating: Data Files/Dataset/Test1803.jpg  \n",
            "  inflating: Data Files/Dataset/Test128.jpg  \n",
            "  inflating: Data Files/Dataset/Test135.jpg  \n",
            "  inflating: Data Files/Dataset/Test236.jpg  \n",
            "  inflating: Data Files/Dataset/Test192.jpg  \n",
            "  inflating: Data Files/Dataset/Test1785.jpg  \n",
            "  inflating: Data Files/Dataset/Test489.jpg  \n",
            "  inflating: Data Files/Dataset/Test1644.jpg  \n",
            "  inflating: Data Files/Dataset/Test238.jpg  \n",
            "  inflating: Data Files/Dataset/Test2280.jpg  \n",
            "  inflating: Data Files/Dataset/Test929.jpg  \n",
            "  inflating: Data Files/Dataset/Test545.jpg  \n",
            "  inflating: Data Files/Dataset/Test225.jpg  \n",
            "  inflating: Data Files/Dataset/Test136.jpg  \n",
            "  inflating: Data Files/Dataset/Test912.jpg  \n",
            "  inflating: Data Files/Dataset/Test1290.jpg  \n",
            "  inflating: Data Files/Dataset/Test117.jpg  \n",
            "  inflating: Data Files/Dataset/Test490.jpg  \n",
            "  inflating: Data Files/Dataset/Test1767.jpg  \n",
            "  inflating: Data Files/Dataset/Test144.jpg  \n",
            "  inflating: Data Files/Dataset/Test2590.jpg  \n",
            "  inflating: Data Files/Dataset/Test2209.jpg  \n",
            "  inflating: Data Files/Dataset/Test211.jpg  \n",
            "  inflating: Data Files/Dataset/Test378.jpg  \n",
            "  inflating: Data Files/Dataset/Test173.jpg  \n",
            "  inflating: Data Files/Dataset/Test941.jpg  \n",
            "  inflating: Data Files/Dataset/Test188.jpg  \n",
            "  inflating: Data Files/Dataset/Test1837.jpg  \n",
            "  inflating: Data Files/Dataset/Test2650.jpg  \n",
            "  inflating: Data Files/Dataset/Test191.jpg  \n",
            "  inflating: Data Files/Dataset/Test3525.jpg  \n",
            "  inflating: Data Files/Dataset/Test149.jpg  \n",
            "  inflating: Data Files/Dataset/Test131.jpg  \n",
            "  inflating: Data Files/Dataset/Test498.jpg  \n",
            "  inflating: Data Files/Dataset/Test360.jpg  \n",
            "  inflating: Data Files/Dataset/Test3277.jpg  \n",
            "  inflating: Data Files/Dataset/Test161.jpg  \n",
            "  inflating: Data Files/Dataset/Test1884.jpg  \n",
            "  inflating: Data Files/Dataset/Test751.jpg  \n",
            "  inflating: Data Files/Dataset/Test668.jpg  \n",
            "  inflating: Data Files/Dataset/Test606.jpg  \n",
            "  inflating: Data Files/Dataset/Test242.jpg  \n",
            "  inflating: Data Files/Dataset/Test1885.jpg  \n",
            "  inflating: Data Files/Dataset/Test993.jpg  \n",
            "  inflating: Data Files/Dataset/Test126.jpg  \n",
            "  inflating: Data Files/Dataset/Test2455.jpg  \n",
            "  inflating: Data Files/Dataset/Test979.jpg  \n",
            "  inflating: Data Files/Dataset/Test824.jpg  \n",
            "  inflating: Data Files/Dataset/Test187.jpg  \n",
            "  inflating: Data Files/Dataset/Test1001.jpg  \n",
            "  inflating: Data Files/Dataset/Test1889.jpg  \n",
            "  inflating: Data Files/Dataset/Test218.jpg  \n",
            "  inflating: Data Files/Dataset/Test1634.jpg  \n",
            "  inflating: Data Files/Dataset/Test228.jpg  \n",
            "  inflating: Data Files/Dataset/Test3159.jpg  \n",
            "  inflating: Data Files/Dataset/Test2791.jpg  \n",
            "  inflating: Data Files/Dataset/Test3294.jpg  \n",
            "  inflating: Data Files/Dataset/Test164.jpg  \n",
            "  inflating: Data Files/Dataset/Test244.jpg  \n",
            "  inflating: Data Files/Dataset/Test237.jpg  \n",
            "  inflating: Data Files/Dataset/Test3893.jpg  \n",
            "  inflating: Data Files/Dataset/Test100.jpg  \n",
            "  inflating: Data Files/Dataset/Test526.jpg  \n",
            "  inflating: Data Files/Dataset/Test614.jpg  \n",
            "  inflating: Data Files/Dataset/Test3024.jpg  \n",
            "  inflating: Data Files/Dataset/Test3934.jpg  \n",
            "  inflating: Data Files/Dataset/Test227.jpg  \n",
            "  inflating: Data Files/Dataset/Test811.jpg  \n",
            "  inflating: Data Files/Dataset/Test3749.jpg  \n",
            "  inflating: Data Files/Dataset/Test122.jpg  \n",
            "  inflating: Data Files/Dataset/Test396.jpg  \n",
            "  inflating: Data Files/Dataset/Test204.jpg  \n",
            "  inflating: Data Files/Dataset/Test835.jpg  \n",
            "  inflating: Data Files/Dataset/Test239.jpg  \n",
            "  inflating: Data Files/Dataset/Test397.jpg  \n",
            "  inflating: Data Files/Dataset/Test176.jpg  \n",
            "  inflating: Data Files/Dataset/Test3798.jpg  \n",
            "  inflating: Data Files/Dataset/Test181.jpg  \n",
            "  inflating: Data Files/Dataset/Test180.jpg  \n",
            "  inflating: Data Files/Dataset/Test945.jpg  \n",
            "  inflating: Data Files/Dataset/Test3130.jpg  \n",
            "  inflating: Data Files/Dataset/Test2007.jpg  \n",
            "  inflating: Data Files/Dataset/Test168.jpg  \n",
            "  inflating: Data Files/Dataset/Test843.jpg  \n",
            "  inflating: Data Files/Dataset/Test2309.jpg  \n",
            "  inflating: Data Files/Dataset/Test677.jpg  \n",
            "  inflating: Data Files/Dataset/Test884.jpg  \n",
            "  inflating: Data Files/Dataset/Test209.jpg  \n",
            "  inflating: Data Files/Dataset/Test859.jpg  \n",
            "  inflating: Data Files/Dataset/Test778.jpg  \n",
            "  inflating: Data Files/Dataset/Test2743.jpg  \n",
            "  inflating: Data Files/Dataset/Test1240.jpg  \n",
            "  inflating: Data Files/Dataset/Test861.jpg  \n",
            "  inflating: Data Files/Dataset/Test624.jpg  \n",
            "  inflating: Data Files/Dataset/Test1818.jpg  \n",
            "  inflating: Data Files/Dataset/Test206.jpg  \n",
            "  inflating: Data Files/Dataset/Test519.jpg  \n",
            "  inflating: Data Files/Dataset/Test374.jpg  \n",
            "  inflating: Data Files/Dataset/Test3360.jpg  \n",
            "  inflating: Data Files/Dataset/Test2424.jpg  \n",
            "  inflating: Data Files/Dataset/Test837.jpg  \n",
            "  inflating: Data Files/Dataset/Test440.jpg  \n",
            "  inflating: Data Files/Dataset/Test3750.jpg  \n",
            "  inflating: Data Files/Dataset/Test221.jpg  \n",
            "  inflating: Data Files/Dataset/Test522.jpg  \n",
            "  inflating: Data Files/Dataset/Test234.jpg  \n",
            "  inflating: Data Files/Dataset/Test143.jpg  \n",
            "  inflating: Data Files/Dataset/Test2962.jpg  \n",
            "  inflating: Data Files/Dataset/Test644.jpg  \n",
            "  inflating: Data Files/Dataset/Test2049.jpg  \n",
            "  inflating: Data Files/Dataset/Test3863.jpg  \n",
            "  inflating: Data Files/Dataset/Test3789.jpg  \n",
            "  inflating: Data Files/Dataset/Test1071.jpg  \n",
            "  inflating: Data Files/Dataset/Test957.jpg  \n",
            "  inflating: Data Files/Dataset/Test165.jpg  \n",
            "  inflating: Data Files/Dataset/Test612.jpg  \n",
            "  inflating: Data Files/Dataset/Test1743.jpg  \n",
            "  inflating: Data Files/Dataset/Test400.jpg  \n",
            "  inflating: Data Files/Dataset/Test3118.jpg  \n",
            "  inflating: Data Files/Dataset/Test3827.jpg  \n",
            "  inflating: Data Files/Dataset/Test1776.jpg  \n",
            "  inflating: Data Files/Dataset/Test231.jpg  \n",
            "  inflating: Data Files/Dataset/Test661.jpg  \n",
            "  inflating: Data Files/Dataset/Test108.jpg  \n",
            "  inflating: Data Files/Dataset/Test760.jpg  \n",
            "  inflating: Data Files/Dataset/Test1992.jpg  \n",
            "  inflating: Data Files/Dataset/Test942.jpg  \n",
            "  inflating: Data Files/Dataset/Test1229.jpg  \n",
            "  inflating: Data Files/Dataset/Test3512.jpg  \n",
            "  inflating: Data Files/Dataset/Test1902.jpg  \n",
            "  inflating: Data Files/Dataset/Test183.jpg  \n",
            "  inflating: Data Files/Dataset/Test2114.jpg  \n",
            "  inflating: Data Files/Dataset/Test1872.jpg  \n",
            "  inflating: Data Files/Dataset/Test250.jpg  \n",
            "  inflating: Data Files/Dataset/Test3975.jpg  \n",
            "  inflating: Data Files/Dataset/Test527.jpg  \n",
            "  inflating: Data Files/Dataset/Test761.jpg  \n",
            "  inflating: Data Files/Dataset/Test1620.jpg  \n",
            "  inflating: Data Files/Dataset/Test2411.jpg  \n",
            "  inflating: Data Files/Dataset/Test834.jpg  \n",
            "  inflating: Data Files/Dataset/Test660.jpg  \n",
            "  inflating: Data Files/Dataset/Test133.jpg  \n",
            "  inflating: Data Files/Dataset/Test160.jpg  \n",
            "  inflating: Data Files/Dataset/Test158.jpg  \n",
            "  inflating: Data Files/Dataset/Test194.jpg  \n",
            "  inflating: Data Files/Dataset/Test1717.jpg  \n",
            "  inflating: Data Files/Dataset/Test216.jpg  \n",
            "  inflating: Data Files/Dataset/Test2068.jpg  \n",
            "  inflating: Data Files/Dataset/Test946.jpg  \n",
            "  inflating: Data Files/Dataset/Test2371.jpg  \n",
            "  inflating: Data Files/Dataset/Test1856.jpg  \n",
            "  inflating: Data Files/Dataset/Test2977.jpg  \n",
            "  inflating: Data Files/Dataset/Test232.jpg  \n",
            "  inflating: Data Files/Dataset/Test665.jpg  \n",
            "  inflating: Data Files/Dataset/Test1199.jpg  \n",
            "  inflating: Data Files/Dataset/Test3864.jpg  \n",
            "  inflating: Data Files/Dataset/Test587.jpg  \n",
            "  inflating: Data Files/Dataset/Test166.jpg  \n",
            "  inflating: Data Files/Dataset/Test3985.jpg  \n",
            "  inflating: Data Files/Dataset/Test154.jpg  \n",
            "  inflating: Data Files/Dataset/Test715.jpg  \n",
            "  inflating: Data Files/Dataset/Test3265.jpg  \n",
            "  inflating: Data Files/Dataset/Test152.jpg  \n",
            "  inflating: Data Files/Dataset/Test1724.jpg  \n",
            "  inflating: Data Files/Dataset/Test1954.jpg  \n",
            "  inflating: Data Files/Dataset/Test249.jpg  \n",
            "  inflating: Data Files/Dataset/Test937.jpg  \n",
            "  inflating: Data Files/Dataset/Test417.jpg  \n",
            "  inflating: Data Files/Dataset/Test201.jpg  \n",
            "  inflating: Data Files/Dataset/Test1161.jpg  \n",
            "  inflating: Data Files/Dataset/Test3566.jpg  \n",
            "  inflating: Data Files/Dataset/Test579.jpg  \n",
            "  inflating: Data Files/Dataset/Test422.jpg  \n",
            "  inflating: Data Files/Dataset/Test3246.jpg  \n",
            "  inflating: Data Files/Dataset/Test1788.jpg  \n",
            "   creating: Data Files/Sample Data Files/\n",
            "  inflating: Data Files/Sample Data Files/Sample_Negative.jpg  \n",
            "  inflating: Data Files/Sample Data Files/Sample_Positive.jpg  \n",
            "  inflating: Data Files/Sample Data Files/Sample_Random.jpg  \n",
            "  inflating: Data Files/Sample_Submission.csv  \n",
            "  inflating: Data Files/Test.csv     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl5v18Ja-m3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "147dee8e-41ea-4c48-d79a-e27ad7b6e90f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOVE\n",
            "Céve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTFB_D-yBgO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4b3a9248-511f-49c3-ed5a-2e1353d58c7b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Data Files/Dataset', [], ['Test522.jpg', 'Test1788.jpg', 'Test1122.jpg', 'Test3130.jpg', 'Test2371.jpg', 'Test1767.jpg', 'Test523.jpg', 'Test2959.jpg', 'Test612.jpg', 'Test942.jpg', 'Test1717.jpg', 'Test1872.jpg', 'Test519.jpg', 'Test660.jpg', 'Test614.jpg', 'Test778.jpg', 'Test396.jpg', 'Test941.jpg', 'Test979.jpg', 'Test946.jpg', 'Test545.jpg', 'Test3246.jpg', 'Test1071.jpg', 'Test213.jpg', 'Test145.jpg', 'Test2007.jpg', 'Test3566.jpg', 'Test1837.jpg', 'Test372.jpg', 'Test154.jpg', 'Test824.jpg', 'Test490.jpg', 'Test812.jpg', 'Test757.jpg', 'Test1776.jpg', 'Test1290.jpg', 'Test109.jpg', 'Test3827.jpg', 'Test498.jpg', 'Test843.jpg', 'Test1803.jpg', 'Test230.jpg', 'Test378.jpg', 'Test579.jpg', 'Test993.jpg', 'Test2235.jpg', 'Test1885.jpg', 'Test232.jpg', 'Test1634.jpg', 'Test1856.jpg', 'Test3789.jpg', 'Test151.jpg', 'Test2209.jpg', 'Test536.jpg', 'Test1785.jpg', 'Test668.jpg', 'Test181.jpg', 'Test789.jpg', 'Test3864.jpg', 'Test100.jpg', 'Test3863.jpg', 'Test890.jpg', 'Test108.jpg', 'Test1229.jpg', 'Test715.jpg', 'Test527.jpg', 'Test1644.jpg', 'Test1743.jpg', 'Test172.jpg', 'Test179.jpg', 'Test779.jpg', 'Test125.jpg', 'Test3985.jpg', 'Test449.jpg', 'Test661.jpg', 'Test835.jpg', 'Test141.jpg', 'Test3118.jpg', 'Test606.jpg', 'Test131.jpg', 'Test3934.jpg', 'Test2309.jpg', 'Test107.jpg', 'Test2114.jpg', 'Test374.jpg', 'Test105.jpg', 'Test581.jpg', 'Test238.jpg', 'Test3030.jpg', 'Test3750.jpg', 'Test422.jpg', 'Test113.jpg', 'Test397.jpg', 'Test243.jpg', 'Test140.jpg', 'Test128.jpg', 'Test242.jpg', 'Test126.jpg', 'Test237.jpg', 'Test3277.jpg', 'Test1161.jpg', 'Test135.jpg', 'Test233.jpg', 'Test173.jpg', 'Test192.jpg', 'Test198.jpg', 'Test194.jpg', 'Test176.jpg', 'Test945.jpg', 'Test231.jpg', 'Test1279.jpg', 'Test1271.jpg', 'Test440.jpg', 'Test132.jpg', 'Test2068.jpg', 'Test1884.jpg', 'Test3294.jpg', 'Test3749.jpg', 'Test957.jpg', 'Test3893.jpg', 'Test133.jpg', 'Test103.jpg', 'Test165.jpg', 'Test1724.jpg', 'Test158.jpg', 'Test1240.jpg', 'Test218.jpg', 'Test221.jpg', 'Test211.jpg', 'Test861.jpg', 'Test859.jpg', 'Test1992.jpg', 'Test811.jpg', 'Test3625.jpg', 'Test353.jpg', 'Test3706.jpg', 'Test122.jpg', 'Test803.jpg', 'Test2049.jpg', 'Test400.jpg', 'Test245.jpg', 'Test526.jpg', 'Test833.jpg', 'Test250.jpg', 'Test2650.jpg', 'Test1022.jpg', 'Test1012.jpg', 'Test1934.jpg', 'Test2616.jpg', 'Test360.jpg', 'Test2791.jpg', 'Test3024.jpg', 'Test2411.jpg', 'Test162.jpg', 'Test225.jpg', 'Test2977.jpg', 'Test417.jpg', 'Test2434.jpg', 'Test1001.jpg', 'Test187.jpg', 'Test751.jpg', 'Test249.jpg', 'Test3798.jpg', 'Test760.jpg', 'Test1902.jpg', 'Test587.jpg', 'Test482.jpg', 'Test834.jpg', 'Test2455.jpg', 'Test160.jpg', 'Test912.jpg', 'Test2590.jpg', 'Test161.jpg', 'Test188.jpg', 'Test227.jpg', 'Test2280.jpg', 'Test937.jpg', 'Test180.jpg', 'Test149.jpg', 'Test1954.jpg', 'Test1818.jpg', 'Test168.jpg', 'Test228.jpg', 'Test129.jpg', 'Test2648.jpg', 'Test1199.jpg', 'Test183.jpg', 'Test2870.jpg', 'Test516.jpg', 'Test644.jpg', 'Test761.jpg', 'Test204.jpg', 'Test152.jpg', 'Test216.jpg', 'Test3975.jpg', 'Test884.jpg', 'Test143.jpg', 'Test201.jpg', 'Test3512.jpg', 'Test244.jpg', 'Test1353.jpg', 'Test533.jpg', 'Test239.jpg', 'Test119.jpg', 'Test164.jpg', 'Test3265.jpg', 'Test1889.jpg', 'Test2962.jpg', 'Test929.jpg', 'Test134.jpg', 'Test2743.jpg', 'Test166.jpg', 'Test3360.jpg', 'Test3525.jpg', 'Test2424.jpg', 'Test1620.jpg', 'Test209.jpg', 'Test234.jpg', 'Test191.jpg', 'Test1923.jpg', 'Test117.jpg', 'Test837.jpg', 'Test240.jpg', 'Test136.jpg', 'Test2792.jpg', 'Test114.jpg', 'Test3177.jpg', 'Test903.jpg', 'Test665.jpg', 'Test206.jpg', 'Test236.jpg', 'Test1359.jpg', 'Test3159.jpg', 'Test144.jpg', 'Test677.jpg', 'Test489.jpg', 'Test1615.jpg', 'Test212.jpg', 'Test624.jpg'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmmi7ap07L3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ebb1ffcb-6184-4b06-b456-496e0dd11e30"
      },
      "source": [
        "import os\n",
        "import pytesseract as pyt\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "text_list=[]\n",
        "filenames=[]\n",
        "images_path=glob.iglob('Data Files/Dataset/*.jpg')\n",
        "\n",
        "for file_name in images_path:\n",
        "  #print(file_name)\n",
        "  text = pyt.image_to_string(Image.open(file_name))\n",
        "  text_list.append(text)\n",
        "  filenames.append(file_name)\n",
        "  \n",
        "'''for file,text in zip(filenames,text_list):\n",
        "   print(file , text)\n",
        "\n",
        "# folder\n",
        "data =os.listdir('Data Files/Dataset/')\n",
        "for filename in os.listdir('Data Files/Dataset/'):\n",
        "  text = pyt.image_to_string(Image.open(data+filename))\n",
        "  print(text)''' "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"for file,text in zip(filenames,text_list):\\n   print(file , text)\\n\\n# folder\\ndata =os.listdir('Data Files/Dataset/')\\nfor filename in os.listdir('Data Files/Dataset/'):\\n  text = pyt.image_to_string(Image.open(data+filename))\\n  print(text)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoZw9xZKChn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "469ab0eb-fd91-47aa-88cf-b55c7e63ef40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC3-yBK95EGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1ae503c8-df02-46fc-fd9d-969c3267bb45"
      },
      "source": [
        "\n",
        "data1=pd.DataFrame(filenames,columns=['filename'])# creating dataframe\n",
        "data1.insert(1, \"text\", text_list, True) # adding text data to dataframe\n",
        "\n",
        "data1.filename=data1.filename.str[19:] # slicing filename \n",
        "\n",
        "dataset=data1[:] # copying dataframe for safety\n",
        "dataset.head() \n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1359.jpg</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test660.jpg</td>\n",
              "      <td>Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test526.jpg</td>\n",
              "      <td>hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test2455.jpg</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test2977.jpg</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename                                               text\n",
              "0  Test1359.jpg                                                   \n",
              "1   Test660.jpg  Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...\n",
              "2   Test526.jpg  hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...\n",
              "3  Test2455.jpg                                                   \n",
              "4  Test2977.jpg                                                   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V0zvcZYQ6dD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "334b39d8-1f6d-40c5-b1e2-2da6534924ee"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpwNIxknRMIz",
        "colab_type": "text"
      },
      "source": [
        "!nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4ZgdVlMP6fE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66e5c086-3258-4c05-acfe-09c1f2b4219b"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu6dtZ5d5QFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "439d978c-5417-4155-f21c-a10f8b5eb098"
      },
      "source": [
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# print(stopwords.words('english'))\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in (df['text']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "        \n",
        "        stops = set(stopwords.words(\"english\"))                  \n",
        "    # \n",
        "        # 5. Remove stop words\n",
        "        meaningful_words = [w for w in words if not w in stops]\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SABAtsSW-4Pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6e7a4905-26d1-4a84-a445-ac5e4fa3e0d5"
      },
      "source": [
        "dataset['preprocessed_text']=clean_sentences(dataset)\n",
        "dataset.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1359.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test660.jpg</td>\n",
              "      <td>Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...</td>\n",
              "      <td>[se, aad, ate, cb, lsu, eer, ee, senn, g, hy, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test526.jpg</td>\n",
              "      <td>hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...</td>\n",
              "      <td>[hledemhenia, leslee, teriebenel, pe, arclenet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test2455.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test2977.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename  ...                                  preprocessed_text\n",
              "0  Test1359.jpg  ...                                                 []\n",
              "1   Test660.jpg  ...  [se, aad, ate, cb, lsu, eer, ee, senn, g, hy, ...\n",
              "2   Test526.jpg  ...  [hledemhenia, leslee, teriebenel, pe, arclenet...\n",
              "3  Test2455.jpg  ...                                                 []\n",
              "4  Test2977.jpg  ...                                                 []\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHGjN__mhNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "ab2c9a72-9ab2-46aa-9ff4-669071465094"
      },
      "source": [
        "# dataset['length']=dataset['preprocessed_text'].str.len()\n",
        "dataset['length'].value_counts()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      112\n",
              "3       12\n",
              "4       11\n",
              "8        9\n",
              "6        8\n",
              "10       8\n",
              "1        7\n",
              "5        7\n",
              "7        6\n",
              "20       5\n",
              "2        4\n",
              "12       4\n",
              "13       4\n",
              "14       4\n",
              "18       4\n",
              "16       3\n",
              "11       3\n",
              "9        3\n",
              "33       3\n",
              "19       2\n",
              "15       2\n",
              "24       2\n",
              "26       2\n",
              "21       1\n",
              "32       1\n",
              "39       1\n",
              "38       1\n",
              "36       1\n",
              "34       1\n",
              "28       1\n",
              "31       1\n",
              "29       1\n",
              "22       1\n",
              "25       1\n",
              "17       1\n",
              "40       1\n",
              "161      1\n",
              "Name: length, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVqvt-7HrEaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "899a99c5-a862-4faf-fe11-6aed2b131cc8"
      },
      "source": [
        "\n",
        "test=dataset[dataset['length']==0] # these are the values with 0 means neutral\n",
        "test.head()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1359.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test2455.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test2977.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Test161.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Test140.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename text preprocessed_text  length\n",
              "0  Test1359.jpg                     []       0\n",
              "3  Test2455.jpg                     []       0\n",
              "4  Test2977.jpg                     []       0\n",
              "5   Test161.jpg                     []       0\n",
              "7   Test140.jpg                     []       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB7yNx7MxvkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c4302cf7-df96-4a5c-da42-dc1939a3a03f"
      },
      "source": [
        "test['sentiment']='Random'\n",
        "test.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>length</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1359.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test2455.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test2977.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Test161.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Test140.jpg</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename text preprocessed_text  length sentiment\n",
              "0  Test1359.jpg                     []       0    Random\n",
              "3  Test2455.jpg                     []       0    Random\n",
              "4  Test2977.jpg                     []       0    Random\n",
              "5   Test161.jpg                     []       0    Random\n",
              "7   Test140.jpg                     []       0    Random"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb23LD_StPv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85c6de50-fc56-4d5e-874e-baa15d0227e9"
      },
      "source": [
        "# train_data=dataset[dataset['length']!=0]\n",
        "train_data.shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(127, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je6ukvgNtxLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_X = tokenizer.texts_to_sequences(train_data['preprocessed_text'])\n",
        "\n",
        "train_data_X = sequence.pad_sequences(train_data_X,maxlen=161)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2OzKeNXu6IM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6856b8e1-33cf-4465-b1d3-c73766a6ce03"
      },
      "source": [
        "pred=model.predict_classes(train_data_X)\n",
        "print(pred)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-93-37e71d3e07d1>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 37) for input Tensor(\"embedding_1_input:0\", shape=(None, 37), dtype=float32), but it was called on an input with incompatible shape (None, 161).\n",
            "[0 0 0 4 0 4 0 4 4 0 4 0 4 4 4 0 0 4 0 4 4 4 4 4 4 4 4 0 4 0 0 0 4 0 4 4 0\n",
            " 4 4 4 4 4 4 4 4 4 0 4 4 0 4 4 4 4 4 4 4 4 0 4 0 4 4 4 0 0 4 4 4 0 0 4 0 4\n",
            " 0 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 0 4 4 4 4 4 4 0 4 4 4 4 4 0 4 4 4 4\n",
            " 4 0 4 0 4 0 4 4 4 4 4 4 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buy_-D8XwDQ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1d88cbac-435e-4967-a625-44119960db40"
      },
      "source": [
        "# train_data['sentiment']=pred\n",
        "# train_data.head()\n",
        "train_data1=train_data[:]\n",
        "train_data1.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>length</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test660.jpg</td>\n",
              "      <td>Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...</td>\n",
              "      <td>[se, aad, ate, cb, lsu, eer, ee, senn, g, hy, ...</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test526.jpg</td>\n",
              "      <td>hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...</td>\n",
              "      <td>[hledemhenia, leslee, teriebenel, pe, arclenet...</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Test523.jpg</td>\n",
              "      <td>Cle) Dy\\nAi GAY\\n\\nera Swan</td>\n",
              "      <td>[cle, dy, ai, gay, era, swan]</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>ees MU WALLA OL\\n\\nem eae ie\\n\\nnot living by ...</td>\n",
              "      <td>[ee, mu, walla, ol, em, eae, ie, living, socie...</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Test668.jpg</td>\n",
              "      <td>@\\n\\nX/hen it come:\\nto the rights of\\n\\nthe U...</td>\n",
              "      <td>[x, hen, come, right, un, anything, neutral, em]</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        filename  ... sentiment\n",
              "1    Test660.jpg  ...         0\n",
              "2    Test526.jpg  ...         0\n",
              "6    Test523.jpg  ...         0\n",
              "8   Test1071.jpg  ...         4\n",
              "11   Test668.jpg  ...         0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKqRP5hVyZ-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e1c9c75b-d1b4-45e5-8bfb-f7dc810a87af"
      },
      "source": [
        "train_data1['sentiment']=train_data1['sentiment'].replace('negative','Negative')\n",
        "train_data1['sentiment']=train_data1['sentiment'].replace('positive','Positive')\n",
        "train_data1.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>length</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test660.jpg</td>\n",
              "      <td>Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...</td>\n",
              "      <td>[se, aad, ate, cb, lsu, eer, ee, senn, g, hy, ...</td>\n",
              "      <td>14</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test526.jpg</td>\n",
              "      <td>hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...</td>\n",
              "      <td>[hledemhenia, leslee, teriebenel, pe, arclenet...</td>\n",
              "      <td>12</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Test523.jpg</td>\n",
              "      <td>Cle) Dy\\nAi GAY\\n\\nera Swan</td>\n",
              "      <td>[cle, dy, ai, gay, era, swan]</td>\n",
              "      <td>6</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>ees MU WALLA OL\\n\\nem eae ie\\n\\nnot living by ...</td>\n",
              "      <td>[ee, mu, walla, ol, em, eae, ie, living, socie...</td>\n",
              "      <td>20</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Test668.jpg</td>\n",
              "      <td>@\\n\\nX/hen it come:\\nto the rights of\\n\\nthe U...</td>\n",
              "      <td>[x, hen, come, right, un, anything, neutral, em]</td>\n",
              "      <td>8</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        filename  ... sentiment\n",
              "1    Test660.jpg  ...  Negative\n",
              "2    Test526.jpg  ...  Negative\n",
              "6    Test523.jpg  ...  Negative\n",
              "8   Test1071.jpg  ...  Positive\n",
              "11   Test668.jpg  ...  Negative\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stpFNKAfsjGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "994812df-c9ae-4509-a273-f03979b5bec8"
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm_qaDpazyZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7959f431-0908-4d26-cf83-aabff0e59f70"
      },
      "source": [
        "result=pd.concat([train_data1,test])\n",
        "result.head()\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>length</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test660.jpg</td>\n",
              "      <td>Se aad\\n\\nate\\nCB LSU\\neer ee a\\nSenn\\n\\n2g) M...</td>\n",
              "      <td>[se, aad, ate, cb, lsu, eer, ee, senn, g, hy, ...</td>\n",
              "      <td>14</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test526.jpg</td>\n",
              "      <td>hLedemhenia\\nLeslee teriebenel\\nPe arcleneteal...</td>\n",
              "      <td>[hledemhenia, leslee, teriebenel, pe, arclenet...</td>\n",
              "      <td>12</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Test523.jpg</td>\n",
              "      <td>Cle) Dy\\nAi GAY\\n\\nera Swan</td>\n",
              "      <td>[cle, dy, ai, gay, era, swan]</td>\n",
              "      <td>6</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>ees MU WALLA OL\\n\\nem eae ie\\n\\nnot living by ...</td>\n",
              "      <td>[ee, mu, walla, ol, em, eae, ie, living, socie...</td>\n",
              "      <td>20</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Test668.jpg</td>\n",
              "      <td>@\\n\\nX/hen it come:\\nto the rights of\\n\\nthe U...</td>\n",
              "      <td>[x, hen, come, right, un, anything, neutral, em]</td>\n",
              "      <td>8</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        filename  ... sentiment\n",
              "1    Test660.jpg  ...  Negative\n",
              "2    Test526.jpg  ...  Negative\n",
              "6    Test523.jpg  ...  Negative\n",
              "8   Test1071.jpg  ...  Positive\n",
              "11   Test668.jpg  ...  Negative\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctv5Z28q1bWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c4e6a03-c6f3-4edb-a113-011412a1a602"
      },
      "source": [
        "# result=result.sort_values(by='filename')\n",
        "result.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(239, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJuqI4m830Zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "187e91b2-58e7-4637-c946-650cbccefd8c"
      },
      "source": [
        "# result=result.rename({'filename':'Filename','sentiment':'Category'})\n",
        "submission=result.drop(['text','preprocessed_text','length'],axis=1)\n",
        "submission.head()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Test100.jpg</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>Test1001.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Test1012.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Test1022.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Test103.jpg</td>\n",
              "      <td>Random</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         filename sentiment\n",
              "77    Test100.jpg    Random\n",
              "208  Test1001.jpg  Positive\n",
              "165  Test1012.jpg  Positive\n",
              "42   Test1022.jpg  Positive\n",
              "38    Test103.jpg    Random"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIHx3saq-wox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8c9c7ba6-0bcc-4213-a8e0-fd82cfa54c13"
      },
      "source": [
        "df1=pd.read_csv('Data Files/Test.csv')\n",
        "df1.head()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1001.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test1012.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test1022.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test1122.jpg</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Filename  Category\n",
              "0  Test1001.jpg       NaN\n",
              "1  Test1012.jpg       NaN\n",
              "2  Test1022.jpg       NaN\n",
              "3  Test1071.jpg       NaN\n",
              "4  Test1122.jpg       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkZ7kSIL-whO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a225ef1-4daf-4ae1-9b06-349cb49e0e85"
      },
      "source": [
        "final=pd.merge(df1,submission,left_on='Filename',right_on='filename',how='left')\n",
        "final.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Category</th>\n",
              "      <th>filename</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Test1001.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test1001.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Test1012.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test1012.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Test1022.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test1022.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test1071.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Test1122.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test1122.jpg</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Filename  Category      filename sentiment\n",
              "0  Test1001.jpg       NaN  Test1001.jpg  Positive\n",
              "1  Test1012.jpg       NaN  Test1012.jpg  Positive\n",
              "2  Test1022.jpg       NaN  Test1022.jpg  Positive\n",
              "3  Test1071.jpg       NaN  Test1071.jpg  Positive\n",
              "4  Test1122.jpg       NaN  Test1122.jpg  Positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xa1a0ZaAkSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# final=final.drop(columns=['Category','filename'],axis=1)\n",
        "# final=final.rename({'sentiment':'Category'},axis=1)\n",
        "final.to_csv('final.csv')\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brj7b6Aa4u6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv('submission.csv')"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buEvN_JQ0fqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5f5c8e60-1542-4369-a964-a7086366a368"
      },
      "source": [
        "from google.colab import files\n",
        "s=files.download('final.csv')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1d6ae216-f25e-42a7-bd96-59078e3eebfb\", \"final.csv\", 5749)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS8LvF_23Gey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33c01613-4e50-4092-c53b-65cf6dd2e113"
      },
      "source": [
        "! git clone https://github.com/johnksander/twitter_NLP_analysis.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'twitter_NLP_analysis'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhMMp0UixPZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab3fff82-7310-43c6-c4b0-8c75c36e6360"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtwitter_NLP_analysis\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ebYejExWez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8901cb04-0f70-4492-b036-19b2969cd73c"
      },
      "source": [
        "ls -lrth twitter_NLP_analysis/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 82M\n",
            "-rwxr-xr-x 1 root root  635 Jul  7 06:41 \u001b[0m\u001b[01;32mMNB_output.txt\u001b[0m*\n",
            "-rwxr-xr-x 1 root root  347 Jul  7 06:41 \u001b[01;32mREADME.md\u001b[0m*\n",
            "-rwxr-xr-x 1 root root 2.3K Jul  7 06:41 \u001b[01;32mbuildWordVec.py\u001b[0m*\n",
            "-rwxr-xr-x 1 root root  42K Jul  7 06:41 \u001b[01;32mbetas.png\u001b[0m*\n",
            "drwxr-xr-x 3 root root 4.0K Jul  7 06:41 \u001b[01;34mdata\u001b[0m/\n",
            "-rwxr-xr-x 1 root root 2.9K Jul  7 06:41 \u001b[01;32mrunMNB.py\u001b[0m*\n",
            "-rwxr-xr-x 1 root root  329 Jul  7 06:41 \u001b[01;32mlasso_output.txt\u001b[0m*\n",
            "-rwxr-xr-x 1 root root 7.5K Jul  7 06:41 \u001b[01;32mfeature_betas.txt\u001b[0m*\n",
            "-rwxr-xr-x 1 root root  82M Jul  7 06:41 \u001b[01;32mtraining.1600000.processed.noemoticon.csv.zip\u001b[0m*\n",
            "-rwxr-xr-x 1 root root 5.0K Jul  7 06:41 \u001b[01;32mtweet_lasso.py\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7LZh6Sxjqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp twitter_NLP_analysis/training.1600000.processed.noemoticon.csv.zip /content/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsaSphmaxp-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36773230-de2f-4cba-9a08-644f397d87b9"
      },
      "source": [
        "ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                                    \u001b[01;34mtwitter_NLP_analysis\u001b[0m/\n",
            "\u001b[01;32mtraining.1600000.processed.noemoticon.csv.zip\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsLTt4ImjzRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv training.1600000.processed.noemoticon.csv.zip tweets.csv.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DyTrunD1R4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9a7a5186-ee4d-48cc-b52b-0e13fb18fae4"
      },
      "source": [
        "!unzip tweets.csv.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tweets.csv.zip\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37t5h3Ey1mTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7934ea76-8a88-4f89-b863-90e8bf765244"
      },
      "source": [
        "ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34m__MACOSX\u001b[0m/     \u001b[01;32mtraining.1600000.processed.noemoticon.csv\u001b[0m*  \u001b[01;34mtwitter_NLP_analysis\u001b[0m/\n",
            "\u001b[01;34msample_data\u001b[0m/  \u001b[01;32mtweets.csv.zip\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw4yuZe31w-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv training.1600000.processed.noemoticon.csv tweets.csv"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnaE-KYh16pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('tweets.csv',encoding='latin-1')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s23Gn3ID1_fN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.rename(columns={'0':'target',\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\" : 'text'})"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2y-FhEC2TVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.drop(columns=['1467810369',\"Mon Apr 06 22:19:45 PDT 2009\",'NO_QUERY','_TheSpecialOne_'],axis=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA58vv0P4GOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7cee65c4-0c23-4313-d70f-2dad86d286b1"
      },
      "source": [
        "data.target.value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    799999\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4mkekgtDk7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGF4BNsY3PK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "39a1b992-fdb0-4c41-c4a7-107f4611e35d"
      },
      "source": [
        "data['clean_sentences']=clean_sentences(data)\n",
        "data.head()  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>[upset, update, facebook, texting, might, cry,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>[kenichan, dived, many, time, ball, managed, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>[nationwideclass, behaving, mad, see]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>[kwesidei, whole, crew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                    clean_sentences\n",
              "0       0  ...  [upset, update, facebook, texting, might, cry,...\n",
              "1       0  ...  [kenichan, dived, many, time, ball, managed, s...\n",
              "2       0  ...             [whole, body, feel, itchy, like, fire]\n",
              "3       0  ...              [nationwideclass, behaving, mad, see]\n",
              "4       0  ...                            [kwesidei, whole, crew]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdQKVsUvUrkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_tweets=data['clean_sentences']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxVBizkuULUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "3f192f61-a0eb-4fd6-e24b-e17303b4a65e"
      },
      "source": [
        "for i in range(len(tokenized_tweets)):\n",
        "    tokenized_tweets[i] = ' '.join(tokenized_tweets[i])    \n",
        "combine['cleanedText'] = tokenized_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-8965146ec07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtokenized_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cleanedText'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3280\u001b[0m                 \u001b[0;31m#  case where it will raise.  (Uh, not clear why)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m                     \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m                     \u001b[0;31m# ref._data.setitem can raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[0;32m-> 3241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVYWn2FD71L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating word Cloud for all Words in all tweets   \n",
        "allWords = ' '.join([text for text in combine['cleanedText']])  # it must be string not tokens\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(allWords)\n",
        "plt.figure(figsize=(10, 10)) \n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\") \n",
        "plt.axis('off') \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHdKu0YATFZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "1adca128-cbb8-4871-d710-04fe527473de"
      },
      "source": [
        "test_data['sentences']=dataset['preprocess_text']\n",
        "\n",
        "allWords = ' '.join([text for text in test_data['sentences']])  # it must be string not tokens\n",
        "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(allWords)\n",
        "plt.figure(figsize=(10, 10)) \n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\") \n",
        "plt.axis('off') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preprocess_text'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-809cd1c3f0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preprocess_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mallWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# it must be string not tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_font_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m110\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preprocess_text'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLDnN2CU__2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=data[:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8R85Y_eAEtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOB3yuVhAN3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train=train.drop(columns='text')\n",
        "train.to_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj8YbxQbAtcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4fd80b5-105c-41c2-c1b4-863f0c83c7dd"
      },
      "source": [
        "from google.colab import files\n",
        "f=files.download('train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a1ef59d7-f1ea-406f-bedc-7de514faf64a\", \"train.csv\", 126568870)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCPSFBV7cegk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "import random\n",
        "# from tensorflow import \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0BXThCJbeh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.utils import to_categorcial\n",
        "\n",
        "target=data.target.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YTP9wJtcBxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_val,Y_train,Y_val=train_test_split(data['clean_sentences'],y_target,test_size=0.2,stratify=y_target)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTkQrZJ6b_a_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39125abd-0807-49b2-ef2e-0b78879a7cc8"
      },
      "source": [
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in (X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "496200\n",
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbzjS_WVcNSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "# tokenizer.fit_on_texts(list(X_val))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu6U0k6LcRZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f46ca139-5be8-4009-e844-8c25c3478d97"
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "# X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
        "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "# X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "\n",
        "print(X_train.shape,X_val.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1279999, 37) (320000, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-U_R64jcV9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
        "callback = [early_stopping]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zPGVd6GLW_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18154850-d433-4993-cdd6-8337b7383fd5"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjv8K8ylLDf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "aa4a3cf2-2bb6-4021-acfc-e63807d127c7"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "# model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "#model.add(LSTM(32,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 37, 300)           148860000 \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 37, 128)           219648    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 149,136,061\n",
            "Trainable params: 149,136,061\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwFe_e5CLeL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7d7f8c9f-955d-4352-c877-7f7156fe26f6"
      },
      "source": [
        "history=model.fit(X_train, Y_train, validation_data=(X_val, Y_val),epochs=1, batch_size=512, verbose=1, callbacks=callback)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500/2500 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.7736WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "2500/2500 [==============================] - 4448s 2s/step - loss: 0.4815 - accuracy: 0.7736 - val_loss: 0.4662 - val_accuracy: 0.7827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDKmUxbeMDoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the weights\n",
        "model.save_weights('./checkpoints/my_checkpoint')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xylahTlkjC90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "070b1178-de8f-4efa-c463-2b1e8a970f1c"
      },
      "source": [
        "ls"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;32mtweets.csv.zip\u001b[0m*\n",
            "\u001b[01;34m__MACOSX\u001b[0m/     \u001b[01;32mtweets.csv\u001b[0m*   \u001b[01;34mtwitter_NLP_analysis\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOnvIoxVjJ6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "adc9728d-1db3-4543-8d1b-940149ab2905"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_model') "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQd_HVCAjhbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a49242cd-88b1-4e7b-9db7-273e693f1f2f"
      },
      "source": [
        "!ls -lrth\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 309M\n",
            "-rwxr-xr-x 1 root root 228M Dec 20  2017 tweets.csv\n",
            "drwxrwxr-x 2 root root 4.0K Dec 20  2017 __MACOSX\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 sample_data\n",
            "drwxr-xr-x 4 root root 4.0K Jul  7 06:41 twitter_NLP_analysis\n",
            "-rwxr-xr-x 1 root root  82M Jul  7 06:41 tweets.csv.zip\n",
            "drwxr-xr-x 2 root root 4.0K Jul  7 09:12 checkpoints\n",
            "drwxr-xr-x 3 root root 4.0K Jul  7 09:14 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlbfMRkCjtoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model.h5') "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cMLlKEtkOyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "27d56aed-1f4c-4e33-8acf-ab536009ad76"
      },
      "source": [
        "ls -lrth"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2.0G\n",
            "-rwxr-xr-x 1 root root 228M Dec 20  2017 \u001b[0m\u001b[01;32mtweets.csv\u001b[0m*\n",
            "drwxrwxr-x 2 root root 4.0K Dec 20  2017 \u001b[01;34m__MACOSX\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4.0K Jun 26 16:26 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4.0K Jul  7 06:41 \u001b[01;34mtwitter_NLP_analysis\u001b[0m/\n",
            "-rwxr-xr-x 1 root root  82M Jul  7 06:41 \u001b[01;32mtweets.csv.zip\u001b[0m*\n",
            "drwxr-xr-x 2 root root 4.0K Jul  7 09:12 \u001b[01;34mcheckpoints\u001b[0m/\n",
            "drwxr-xr-x 3 root root 4.0K Jul  7 09:14 \u001b[01;34msaved_model\u001b[0m/\n",
            "-rw-r--r-- 1 root root 1.7G Jul  7 09:17 my_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dImI0V4bkVG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
