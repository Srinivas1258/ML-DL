{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dance_form_GPU.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf-3j01T8Dtb",
        "colab_type": "text"
      },
      "source": [
        "Installing the necessary libraries through commands prompt.\n",
        "\n",
        "! -command mode\n",
        "- edit mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlmGFNmonJAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install keras-resnet "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOJ8zfhina7m",
        "colab_type": "text"
      },
      "source": [
        "In order to import/export files from/to local system we have to use \n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()//files.download()\n",
        "\n",
        "You can access files in Drive in a number of ways, including:\n",
        "\n",
        "Mounting your Google Drive in the runtime's virtual machine\n",
        "\n",
        "Using a wrapper around the API such as PyDrive\n",
        "\n",
        "Using the native REST API\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6oGvdnunhOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwvFVeauBwk4",
        "colab_type": "text"
      },
      "source": [
        "Unzip using the above file using below command.\n",
        "\n",
        "!unzip hacker.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S33E7OPhoaGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip hacker.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c25sbLmZqk6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls  # list of files in the path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7S7ehPGvFUn",
        "colab_type": "text"
      },
      "source": [
        "Import Essential libraries needed for Cnn Image classification.\n",
        "\n",
        "1.import all libraries either from keras.model or tensorflow.keras.model\n",
        "\n",
        "2.if u combine above these two u will get class instance error\n",
        "\n",
        "**The added layer must be an instance of class Layer. Found: <tensorflow.python.keras.engine.input_layer.InputLayer>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY7d-oiSpgJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Flatten,BatchNormalization,Dropout,Activation\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import optimizers\n",
        "import cv2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YTbYSm7DNjO",
        "colab_type": "text"
      },
      "source": [
        "Here we are using Resnet-50 for transfer learning (pre-trained model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzUZBNWOwOQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnzDUiqxOc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDJU4HKSA5Rt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('dataset/train.csv') # read .csv file using pandas as dataframe\n",
        "test=pd.read_csv('dataset/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "752bRdsraidv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install scikit-learn  # installing scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_dmNMDDxQ-",
        "colab_type": "text"
      },
      "source": [
        "In order to convert the output labels to integers and vectors\n",
        "\n",
        "\n",
        "*   Converting into integers using label encoder\n",
        "\n",
        "*   then convert integers into vectors using one hot encoder / from keras we can done using to_categorical\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfoHfmJy_8C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le =LabelEncoder()\n",
        "le.fit(train.target)\n",
        "train['target1']=le.transform(train.target)\n",
        "#X_train,X_valid,y_train,y_valid =train_test_split(train.Image,train.target,test_size=0.1,stratify=train.target)\n",
        "train['target1']=to_categorical(train['target'])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJzBKJ1zE_-6",
        "colab_type": "text"
      },
      "source": [
        "Either we can convert the output label into vectors and feed into into neural network through the training generator - (class_mode -raw,\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "y_col =[columns of vectors of output labels]\n",
        "\n",
        "columns=['bharatanatyam','kathak','kathakali','kuchipudi','manipuri','mohiniyattam','odissi','sattriya']\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = pd.DataFrame(enc.fit_transform(train[['target']]).toarray())\n",
        "# merge with main df bridge_df on key values\n",
        "train = train.join(enc_df)**bold text**\n",
        "\n",
        "# This is formatted as code\n",
        "```train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train,\n",
        "directory=\"dataset/train/\",\n",
        "x_col='Image',\n",
        "y_col=columns,\n",
        "subset=\"training\",\n",
        "batch_size=8,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"raw\",\n",
        "target_size=(224,224))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioCQRxH9GoRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhcYM5fsGhDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "train_dir='dataset/train/'\n",
        "X_set = []\n",
        "IMG_SIZE = 224\n",
        "for index,row in train.iterrows():\n",
        "    print(f'\\rDone: {os.path.join(train_dir,row[0])}',end='')\n",
        "    img = cv2.imread(os.path.join(train_dir,row[0]))\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    X_set.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBqY01mm3Z5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X_set)\n",
        "y = train['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSIBJCYfIrXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrsqViODIvjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = enc.fit_transform(train[['target']]).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSCRPdt6JW_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKGEN0YM3027",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X[0])\n",
        "plt.title(f'{y[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17g84L4iJJof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.17, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71b4ng1ZJYBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                             rotation_range=20,\n",
        "                             zoom_range=0.2,\n",
        "                             width_shift_range = 0.2,\n",
        "                             height_shift_range = 0.2,\n",
        "                             shear_range=0.1,\n",
        "                             fill_mode=\"nearest\")\n",
        "\n",
        "testgen = ImageDataGenerator()\n",
        "\n",
        "datagen.fit(X_train)\n",
        "testgen.fit(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT1bjeJ44k1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_Height=224\n",
        "IMG_Width=224\n",
        "input_size=(IMG_Height,IMG_Width,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFK_rxZYJiUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras\n",
        "\n",
        "inception=InceptionV3(include_top=False,weights='imagenet',input_shape=input_size)\n",
        "output1=inception.output\n",
        "output1=GlobalAveragePooling2D()(output1)\n",
        "output1=Dense(512, activation='relu')(output1)\n",
        "predictions = Dense(8, activation='softmax')(output1)\n",
        "inception=Model(inception.input,predictions)\n",
        "for layers in inception.layers:\n",
        "  layers.trainable=False\n",
        "inception.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVyTsX7V5RA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "model2 = Sequential()\n",
        "model2.add(inception)\n",
        "# model2.add(Conv2D(256,kernel_size=3,padding='same',activation='relu',input_shape=(224,224,3)))\n",
        "# model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "# model2.add(Dropout(0.25))\n",
        "# model2.add(Flatten())\n",
        "# model2.add(Dense(1024, activation='relu', input_dim=(224,224,3)))\n",
        "# model2.add(Dense(1024,activation='relu'))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(Dropout(0.3))\n",
        "# model2.add(Dense(512, activation='relu'))\n",
        "# model2.add(BatchNormalization())\n",
        "# model2.add(Dropout(0.3))\n",
        "# model2.add(GlobalAveragePooling2D())\n",
        "model2.add(Dense(8, activation='softmax')) '''\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD3-iDRFJp3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                           patience=3,\n",
        "                                           verbose=1,\n",
        "                                           factor=0.5,\n",
        "                                           min_lr=0.0001)\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        " \n",
        "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-6WYn26hZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_list=[cb_early_stopper,cb_checkpointer,learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17iXD1za6Req",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model2.fit_generator(datagen.flow(X_train,y_train,batch_size=32),\n",
        "                                        validation_data=testgen.flow(X_test,y_test,batch_size=32),\n",
        "                                        epochs=50)\n",
        "                                        # callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knGkIhpfL7-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_labels=train.target.values\n",
        "le =LabelEncoder()\n",
        "le.fit(train.target)\n",
        "train['target2']=le.transform(train.target)\n",
        "train_Label=to_categorical(train.target2)\n",
        "train_Label.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv5a7lasLChh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.target1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jqiFemkapKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = pd.DataFrame(enc.fit_transform(train[['target']]).toarray())\n",
        "# merge with main df bridge_df on key values\n",
        "train = train.join(enc_df)\n",
        "train\n",
        "#y=train.iloc[:,2:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC1ZnwyUP0BQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train.head(10)\n",
        "train=train.rename({0:'bharatanatyam',1:'kathak',2:'kathakali',3:'kuchipudi',4:'manipuri',5:'mohiniyattam',6:'odissi',7:'sattriya'},axis=1)\n",
        "train.head()\n",
        "columns=['bharatanatyam','kathak','kathakali','kuchipudi','manipuri','mohiniyattam','odissi','sattriya']\n",
        "'''from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc_df = pd.DataFrame(enc.fit_transform(train[['target']]).toarray())\n",
        "# merge with main df bridge_df on key values\n",
        "train = train.join(enc_df)\n",
        "train '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pq1efdZTOPc",
        "colab_type": "text"
      },
      "source": [
        "In order to do image data preprocessing best way to do is \n",
        "\n",
        "1.ImageDataGenerator - Data augmentation(train,test,valid data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,  - normalizing the image b/w 0 to 1\n",
        "        shear_range=0.2,   - shear transformation\n",
        "        zoom_range=0.2,     - zooming the image by 20%\n",
        "        horizontal_flip=True)  - rotating\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)'''\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "2.flow from\n",
        "\n",
        "2.1  flow_from_directory -images paths like this\n",
        "   \n",
        "main_directory/\n",
        "\n",
        "  ...class_a/\n",
        "\n",
        "      ......a_image_1.jpg\n",
        "\n",
        "      ......a_image_2.jpg\n",
        "\n",
        "  ...class_b/\n",
        "\n",
        "    ......b_image_1.jpg\n",
        "\n",
        "    ......b_image_2.jpg\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "```\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'data/train',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'data/validation',\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "*   flow from dataframe  - there is dataframe like train.csv\n",
        " \n",
        " it contain - Image name -1.jpg,2.jpg...\n",
        "             \n",
        "             target  -Kathakali,manipuri...etc\n",
        "\n",
        "  \n",
        "\n",
        "```\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train, # dataframe name\n",
        "directory=\"dataset/train/\", - directory of images located\n",
        "x_col='Image', - images names in dataframe\n",
        "y_col=columns,  - target label\n",
        "subset=\"training\", - \n",
        "batch_size=8,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"raw\", - \"raw\" data if output is in vectors ,\"categorical\" if output is categorical or string. \n",
        "target_size=(224,224)) - shape of image of after passing through generator\n",
        "```\n",
        "\n",
        "\n",
        "other techniques are also there plz refer keras documentation \n",
        "[keras documentation](https://keras.io/api/preprocessing/image/)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maisjB5G_r1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)'''\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.05,shear_range=0.2,\n",
        "    zoom_range=0.2)\n",
        "\n",
        "\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train,\n",
        "directory=\"dataset/train/\",\n",
        "x_col='Image',\n",
        "y_col='target',\n",
        "subset=\"training\",\n",
        "batch_size=8,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224,224))\n",
        "\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train,\n",
        "directory=\"dataset/train/\",\n",
        "x_col='Image',\n",
        "y_col='target',\n",
        "subset=\"validation\",\n",
        "batch_size=8,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224,224))\n",
        "\n",
        "#test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=test,\n",
        "directory=\"dataset/test/\",\n",
        "x_col=\"Image\",\n",
        "y_col=None,\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=(224,224))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujlYBJwzLshq",
        "colab_type": "text"
      },
      "source": [
        "While we are dealing with tranfer learning or pretrained modes like resnet,vgg6,inception..\n",
        "\n",
        "We will remve the top layer of pretrained model - Fully connected layer  -**include_top=False**\n",
        "\n",
        "rest of them we will keep as it is ...\n",
        "1. weights are pretrained except top layer  - **weights='imagenet'**\n",
        "2. Make all the layers non-trainable (We can retrain some of the lower layers to increase performance. Keep in mind that this may lead to overfitting)\n",
        "\n",
        "\n",
        "```\n",
        "for layer in restnet.layers:\n",
        "    layer.trainable = False\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "output = restnet.layers[-1].output\n",
        "output = keras.layers.Flatten()(output) # giving the resnet-output to keras flatten layer(giving custom output to pretrained model) \n",
        "restnet = Model(restnet.input, output=output)\n",
        "for layer in restnet.layers: \n",
        "    layer.trainable = False     # Make all the layers non-trainable (We can retrain some of the lower layers to increase performance. Keep in mind that this may lead to overfitting)\n",
        "\n",
        "restnet.summary()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-luuuTkimL5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model\n",
        "import keras\n",
        "\n",
        "inception=InceptionV3(include_top=False,weights='imagenet',input_shape=(224,224,3))\n",
        "output1=inception.layers[-1].output\n",
        "output1=keras.layers.Flatten()(output1)\n",
        "inception=Model(inception.input,output=output1)\n",
        "for layers in inception.layers:\n",
        "  layers.trainable=False\n",
        "inception.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmksT-40_rgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "import keras\n",
        "restnet = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
        "output = restnet.layers[-1].output\n",
        "output = keras.layers.Flatten()(output)\n",
        "restnet = Model(restnet.input, output=output)\n",
        "for layer in restnet.layers:\n",
        "    layer.trainable = False\n",
        "restnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhb1yoLyOx-Z",
        "colab_type": "text"
      },
      "source": [
        "Custom keras model on the top of pretrained resnet model.\n",
        "\n",
        " for binary output loss - binary_crossentropy\n",
        " for muli-output   loss -categorical crossentropy\n",
        " optimizers -adam,adagrad, rmsprop\n",
        " metrics  -accuracy\n",
        "```\n",
        "# This is formatted as code\n",
        "\n",
        "\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.SGD(learning_rate=1e-3, decay=1e-6,  momentum = 0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbS9dqxyOx2b",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2g4w1PnCvo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, InputLayer,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(inception)\n",
        "# model2.add(Conv2D(256,kernel_size=3,padding='same',activation='relu',input_shape=(224,224,3)))\n",
        "# model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "# model2.add(Dropout(0.25))\n",
        "# model2.add(Flatten())\n",
        "model2.add(Dense(1024, activation='relu', input_dim=(224,224,3)))\n",
        "# model2.add(Dense(1024,activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.3))\n",
        "model2.add(Dense(8, activation='softmax'))\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_-jDdXTAfPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model2.fit_generator(train_generator,\n",
        "        validation_data = test_generator,\n",
        "        epochs = 20,\n",
        "        steps_per_epoch = len(train_generator),\n",
        "        validation_steps = len(test_generator),\n",
        "        \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgOOejTbCvam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model2.fit(train_generator,\n",
        "                               \n",
        "                              epochs=10,\n",
        "                              validation_data=valid_generator, \n",
        "                      \n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGb_QteEP4Bh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   **.fit** is used when the entire training dataset can fit into the memory and no data augmentation is applied.\n",
        "\n",
        "\n",
        "*   **.fit_generator** is used when either we have a huge dataset to fit into our memory or when data augmentation needs to be applied.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFu5rNgkDPRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate =model2.evaluate_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWxdBpvhCvLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "pred=model2.predict_generator(test_generator,\n",
        "verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upQMJai1RQsL",
        "colab_type": "text"
      },
      "source": [
        "In order to view predctions we use this below the code \n",
        "\n",
        "generating the predictions file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mTdR2RK37o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Image\":filenames,\n",
        "                      \"target\":predictions})\n",
        "results.to_csv(\"results.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLdZAGk51BDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k in predicted_class_indices:\n",
        "  print (k, labels[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drWEJuhsR9Ib",
        "colab_type": "text"
      },
      "source": [
        "to download the results .csv from collab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8SOAw9fLkw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('results.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKnabE_MSEpe",
        "colab_type": "text"
      },
      "source": [
        "some pre-checks to stop overfitting the model. -**EarlyStopping, ModelCheckpoint**\n",
        "\n",
        "Loads the weights of model to save in future to skip training.\n",
        "\n",
        "\n",
        "```\n",
        "#model1.load_weights(\"../working/best.hdf5\")\n",
        "\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\n",
        "\n",
        "fit_history = model1.fit_generator(\n",
        "        train_generator,\n",
        "        \n",
        "        epochs = 10,\n",
        "        validation_data=validation_generator,\n",
        "        \n",
        "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
        ")\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t5ZAOQHSzLy",
        "colab_type": "text"
      },
      "source": [
        "To view the performacne metrics like validation accurracy,loss vs epochs \n",
        "\n",
        "fit_history is model name \n",
        "\n",
        "```\n",
        "acc=fit_history.history['accuracy']    - modelname.history['accuracy']\n",
        "val_acc=fit_history.history['val_accuracy']\n",
        "loss=fit_history.history['loss']\n",
        "val_loss=fit_history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('../Accuracy_curve_CNN_256.jpg')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buIQmnKn3Kap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('../Accuracy_curve_CNN_256.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZOOjQ81TYZT",
        "colab_type": "text"
      },
      "source": [
        "Custom model for image classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ5PBVHcp1lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=64,kernel_size=3,padding='same',input_shape=(150,150,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=2))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64,kernel_size=3))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(8,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqyvcZhsqD57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "''' model.fit(train_generator, epochs=10,\n",
        "                              batch_size=32,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator\n",
        "                            \n",
        "                              ) '''\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights.hdf5', monitor='val_loss',\n",
        "save_best_only=True)\n",
        "# Store in a list to be used during training\n",
        "#callbacks_list = [checkpoint]\n",
        "# Fit the model on a training set, using the checkpoint as a\n",
        "#callback\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=10,\n",
        "                              \n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator\n",
        "                            \n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thfNF9n-qYc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=history.history['acc']\n",
        "val_acc=model.history['val_acc']\n",
        "loss=model.history['loss']\n",
        "val_loss=model.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs, acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "fig.savefig('../Accuracy_curve_CNN_256.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}